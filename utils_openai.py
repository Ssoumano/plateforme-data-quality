# utils_openai.py

from openai import OpenAI
from typing import Dict, Optional
import pandas as pd


def get_openai_client(api_key: Optional[str] = None) -> OpenAI:
    """
    Cr√©e un client OpenAI.
    
    Args:
        api_key: Cl√© API OpenAI (optionnel si d√©finie en variable d'environnement)
        
    Returns:
        OpenAI: Client OpenAI initialis√©
    """
    if api_key:
        return OpenAI(api_key=api_key)
    return OpenAI()  # Utilise la variable d'environnement OPENAI_API_KEY


def generate_synthesis(client: OpenAI, df: pd.DataFrame, profil: Dict) -> str:
    """
    G√©n√®re une synth√®se professionnelle de la qualit√© des donn√©es via IA.
    
    Args:
        client: Client OpenAI
        df: DataFrame analys√©
        profil: Dictionnaire de profil de qualit√©
        
    Returns:
        str: Synth√®se en markdown
    """
    # Cr√©er un √©chantillon du sch√©ma avec exemples
    schema_samples = []
    for col in df.columns[:20]:  # Limiter √† 20 colonnes pour le prompt
        sample_values = df[col].dropna().head(3).tolist()
        dtype = profil["dtypes"][col]
        missing_pct = profil["missing_pct"][col]
        
        schema_samples.append(
            f"- **{col}** ({dtype}): {sample_values} | Valeurs manquantes: {missing_pct}%"
        )
    
    schema_text = "\n".join(schema_samples)
    
    # Construire le contexte d√©taill√©
    context = f"""
## DATASET ANALYS√â

**Dimensions:**
- Lignes: {profil['rows']:,}
- Colonnes: {profil['cols']}
- Taille m√©moire: {profil.get('memory_usage', 0):.2f} MB

**Qualit√© globale:**
- Score global: {profil['global_score']}%
- Taux de valeurs manquantes: {profil['missing_rate']:.2f}%
- Nombre total de valeurs manquantes: {profil['total_missing']:,}
- Lignes dupliqu√©es: {profil['duplicate_rows']} ({profil['duplicate_rate']:.2f}%)

**Distribution des types de colonnes:**
{profil.get('type_distribution', {})}

**Probl√®mes identifi√©s:**
- Colonnes constantes: {len(profil['constant_columns'])}
- Colonnes vides: {len(profil['empty_columns'])}
- Colonnes √† haute cardinalit√©: {len(profil.get('high_cardinality_cols', []))}
- Total d'outliers: {profil.get('total_outliers', 0)}

**√âchantillon du sch√©ma (premi√®res colonnes):**
{schema_text}

**Scores d√©taill√©s:**
{profil.get('score_details', {})}
"""

    prompt = f"""
Tu es un **consultant expert en Data Quality et Data Engineering** avec 15 ans d'exp√©rience.

Voici le contexte complet d'un dataset que tu dois analyser:

{context}

**TA MISSION:**

1) **Synth√®se Professionnelle** (12-18 lignes)
   - Commence par une √©valuation globale du score de qualit√©
   - Identifie les 3 probl√®mes majeurs par ordre de criticit√©
   - Explique l'impact m√©tier de ces probl√®mes
   - Utilise un ton professionnel mais accessible
   - Utilise des emojis pertinents pour la lisibilit√© (‚ö†Ô∏è üîç ‚úÖ üìä)

2) **Tableau de Priorisation**
   Cr√©e un tableau markdown avec ces colonnes:
   | Priorit√© | Probl√®me | Colonnes concern√©es | Impact | Recommandation |
   
   Inclus 5-7 lignes par ordre de priorit√© d√©croissante.

3) **Quick Wins** (5 actions rapides)
   Liste 5 actions concr√®tes et imm√©diatement applicables avec:
   - üéØ Action
   - üí° B√©n√©fice attendu
   - ‚è±Ô∏è Effort estim√© (Faible/Moyen/√âlev√©)

4) **Tests de Qualit√© Recommand√©s**
   Sugg√®re 3-5 tests automatis√©s √† mettre en place

**FORMAT DE R√âPONSE:**
Utilise le markdown avec des sections claires, des tableaux, et des listes √† puces.
Sois concret, actionnable et professionnel.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system", 
                    "content": "Tu es un consultant expert en Data Quality avec une expertise approfondie en analyse de donn√©es, data engineering et gouvernance des donn√©es. Tu fournis des analyses professionnelles, actionnables et orient√©es business."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            max_tokens=1500,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"‚ùå **Erreur lors de la g√©n√©ration de la synth√®se:**\n\n{str(e)}"


def generate_tests(client: OpenAI, df: pd.DataFrame) -> str:
    """
    G√©n√®re des tests de qualit√© de donn√©es adapt√©s au dataset.
    
    Args:
        client: Client OpenAI
        df: DataFrame √† tester
        
    Returns:
        str: Liste de tests en markdown
    """
    # Cr√©er un aper√ßu du sch√©ma
    schema_info = []
    for col in df.columns[:15]:
        dtype = str(df[col].dtype)
        nunique = df[col].nunique()
        missing = df[col].isna().sum()
        sample = df[col].dropna().head(2).tolist()
        
        schema_info.append(
            f"- **{col}** ({dtype}): {nunique} valeurs uniques, {missing} NaN | Ex: {sample}"
        )
    
    schema_text = "\n".join(schema_info)
    
    prompt = f"""
Tu es un expert en **Data Quality Testing** et en automatisation de tests.

Voici le sch√©ma d'un dataset √† tester:

**Dimensions:** {len(df)} lignes √ó {len(df.columns)} colonnes

**Colonnes:**
{schema_text}

**TA MISSION:**

Propose **8 tests de qualit√© des donn√©es** sp√©cifiquement adapt√©s √† ce dataset.

Pour CHAQUE test, fournis:

### Test N: [Nom descriptif du test]

- **Objectif:** Pourquoi ce test est important
- **Crit√®re de succ√®s:** Conditions pr√©cises pour passer le test
- **Colonnes concern√©es:** Liste des colonnes √† tester
- **S√©v√©rit√©:** Critique / Majeure / Mineure
- **Code Python (exemple):**
```python
# Code de test concret et ex√©cutable
```

**TYPES DE TESTS √Ä COUVRIR:**
1. Compl√©tude (valeurs manquantes)
2. Validit√© (format, plage de valeurs)
3. Coh√©rence (relations entre colonnes)
4. Unicit√© (doublons, cl√©s)
5. Exactitude (valeurs aberrantes)
6. Conformit√© (r√®gles m√©tier)

Sois **TR√àS SP√âCIFIQUE** aux colonnes et types de ce dataset.
Fournis du code Python **EX√âCUTABLE** utilisant pandas.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "Tu es un expert en tests de qualit√© de donn√©es et en validation de datasets. Tu cr√©es des tests concrets, ex√©cutables et adapt√©s au contexte sp√©cifique de chaque dataset."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=2000,
            temperature=0.6
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"‚ùå **Erreur lors de la g√©n√©ration des tests:**\n\n{str(e)}"


def generate_cleaning_script(client: OpenAI, df: pd.DataFrame, profil: Dict) -> str:
    """
    G√©n√®re un script Python complet de nettoyage des donn√©es.
    
    Args:
        client: Client OpenAI
        df: DataFrame √† nettoyer
        profil: Profil de qualit√©
        
    Returns:
        str: Script Python comment√©
    """
    problems = []
    
    if profil["empty_columns"]:
        problems.append(f"Colonnes vides: {profil['empty_columns']}")
    
    if profil["constant_columns"]:
        problems.append(f"Colonnes constantes: {profil['constant_columns']}")
    
    if profil["duplicate_rows"] > 0:
        problems.append(f"{profil['duplicate_rows']} lignes dupliqu√©es")
    
    high_missing = profil["missing_pct"][profil["missing_pct"] > 30]
    if not high_missing.empty:
        problems.append(f"Colonnes avec >30% de NaN: {high_missing.index.tolist()}")
    
    problems_text = "\n".join([f"- {p}" for p in problems])
    
    prompt = f"""
G√©n√®re un script Python complet et ex√©cutable pour nettoyer ce dataset.

**Probl√®mes identifi√©s:**
{problems_text}

**Dimensions:** {profil['rows']} lignes √ó {profil['cols']} colonnes

Le script doit:
1. √ätre enti√®rement comment√©
2. Utiliser pandas
3. G√©rer chaque probl√®me identifi√©
4. Inclure des v√©rifications avant/apr√®s
5. √ätre ex√©cutable tel quel

Format: Code Python pur avec commentaires d√©taill√©s.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "Tu es un expert en data cleaning et pr√©paration de donn√©es. Tu √©cris du code Python propre, comment√© et ex√©cutable."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=1500,
            temperature=0.5
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"# Erreur lors de la g√©n√©ration du script:\n# {str(e)}"
